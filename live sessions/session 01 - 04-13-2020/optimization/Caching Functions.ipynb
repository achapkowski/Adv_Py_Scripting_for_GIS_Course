{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization of Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips and Tricks : Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Caching?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/cache_bro.png\"/>\n",
    "\n",
    "- Saves the return values of some function calls, queries or HTTP requests, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Cases for Caching?\n",
    "\n",
    "- What do you do when code takes too long to compute?\n",
    "- What do you do when a call is repeated multiple times? (and get the same result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. the function is deterministic and the results have the same value **every time** given the same inputs\n",
    "2. the return value of the function is nondeterministic but continues to be useful and valid for a given period of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidates for Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Results from callables that query databases\n",
    "2. Results that render static values: ie Web Requests, PDF Rendering, file content\n",
    "    - Can improve performance and reduce network slowness\n",
    "3. Results from **deterministic** calls that perform **complex** calculations\n",
    "4. Global mappings that keep track of values with expiration times, like sessions and token expirations\n",
    "5. Results that need to accessed often and quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- implemented many different ways\n",
    "- common way is to use `dict` data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- easy and safe way of caching\n",
    "- always return the same value given the same inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    \"\"\"\n",
    "    Returns the Nth Fibonacci Sequence Number Using Recursion\n",
    "    \n",
    "    :returns: Float\n",
    "    \"\"\"\n",
    "    if n < 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can `fib` get Cached?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fibonacci Visualized** \n",
    "<img src=\"./img/fib_diagram.png\" width=75%/>\n",
    "\n",
    "- As we moved down the called `fib`, the same method gets called multiple times but returns the same results\n",
    "- This makes it a good candidate for caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "\n",
    "- Python evaluates instructions from left to right.\n",
    "- This means, in this situation of the `fib` method the call to the higher value will happen before the lower n value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Decorator to Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memorize_it(fn):\n",
    "    \"\"\"\n",
    "    saves the call's argument function and result\n",
    "    \"\"\"\n",
    "    call_cache = {}\n",
    "    \n",
    "    def memorized(argument):\n",
    "        try:\n",
    "            return call_cache[argument]\n",
    "        except KeyError:\n",
    "            return call_cache.setdefault(argument, fn(argument))\n",
    "    return memorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib2(n):\n",
    "    \"\"\"\n",
    "    Returns the Nth Fibonacci Sequence Number Using Recursion\n",
    "    \n",
    "    :returns: Float\n",
    "    \"\"\"\n",
    "    if n < 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memorize_it\n",
    "def fib(n):\n",
    "    \"\"\"\n",
    "    Returns the Nth Fibonacci Sequence Number Using Recursion\n",
    "    \n",
    "    :returns: Float\n",
    "    \"\"\"\n",
    "    if n < 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit fib(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit fib2(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Going on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/dude.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the decorator simple saves the inputs and output into the `dict` variable\n",
    "- this works for this case, but not all cases\n",
    "- luckily for us, the Python core library has built-in caching!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `lru_cache` Decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If *maxsize* is set to None, the LRU features are disabled and the cache\n",
    "can grow without bound.\n",
    "\n",
    "- If *typed* is True, arguments of different types will be cached separately.\n",
    "    + For example, f(3.0) and f(3) will be treated as distinct calls with distinct results.\n",
    "\n",
    "- Arguments to the cached function must be hashable.\n",
    "\n",
    "- View the cache statistics named tuple (hits, misses, maxsize, currsize) with f.cache_info().  Clear the cache and statistics with f.cache_clear(). Access the underlying function with `f.__wrapped__`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(5, True)  # saves last 5 calls sensative to input types\n",
    "def fib3(n):\n",
    "    \"\"\"\n",
    "    Returns the Nth Fibonacci Sequence Number Using Recursion\n",
    "    \n",
    "    :returns: Float\n",
    "    \"\"\"\n",
    "    if n < 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib3(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib3.cache_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib3.cache_clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-deterministic Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The trick with this caching method is to know when the cache should be cleared.\n",
    "- Because each result could be different, ensure cache is long lived enough to be helpful, but short enough to prevent new data from coming in.\n",
    "- These methods tend to be hard to track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Options:\n",
    "\n",
    "1. Modify `lru_cache`\n",
    "2. Use a 3rd Party Module:\n",
    "    - PiPy Search: https://pypi.org/search/?q=caching\n",
    "    - A github project on caching: https://github.com/tkem/cachetools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- caching is efficient as long as the time is taken to interact with cache is **less than** the time the cached function takes to execute\n",
    "- caching is normally done when communicating with external systems\n",
    "    + caching has it's own costs\n",
    "- If doing non-deterministic caching, ensure you do it carefully.  This will have consequences down stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/woohoo.jpg\" >"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
